{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Bayesian Phylogenetics in Linguistics explained\n",
    "\n",
    "This is a Jupyter notebook that shows you a very simplified example of Bayesian phylogenetics in linguistics, step by step, from the initial data to a resulting summary tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Program libraries\n",
    "The code here is written in Python. Python comes with a lot of libraries to deal with numerical processes, trees, plotting, and so on; I load them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy, ete3, newick, pandas as pd\n",
    "DF = pd.DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "from helpers import roll_die"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Language data\n",
    "\n",
    "Now let us do some Bayesian phylogenetics, starting from a very simple and constructed example. Let us say we have some data like this.\n",
    "\n",
    "I use lexical data in my example because it is the data type best understood for computational models. The methodology is not specific to it, as I will explain below; Having a different type of data, and corresponding models of language change, will mean that the rest of the methodology can be applied equivalently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Kalang    Nda'o Sunggama   Ta'e\nchild  tuˈmun     ˈana     anˈa   ˈana\nmoon      pak    ˈwuɹa    wuˈla  ˈʋula\nflat    ˈrata  ˈn͡dena    deˈna  ˈrata"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DF({\n",
    "  \"Kalang\": ['tuˈmun', 'pak', 'ˈrata'],\n",
    "  \"Ta'e\": ['ˈana', 'ˈʋula', 'ˈrata'],\n",
    "  \"Sunggama\": ['anˈa', 'wuˈla', 'deˈna'],\n",
    "  \"Nda'o\": ['ˈana', 'ˈwuɹa', 'ˈn͡dena']},\n",
    "  index=[\"child\", \"moon\", \"flat\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "I will not explain automatic cognate coding in this notebook, so let us for now assume that it can be done and that automatic or manual cognate coding gives us the following cognate table corresponding to the one above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Kl  Nd  Sg  Ta\n0   1   2   2   2\n1   1   2   2   2\n2   1   2   2   1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DF({\n",
    "  \"Kl\": [1, 1, 1],\n",
    "  \"Ta\": [2, 2, 1],\n",
    "  \"Sg\": [2, 2, 2],\n",
    "  \"Nd\": [2, 2, 2]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Stochastic processes for creating trees\n",
    "\n",
    "The basic mathematical theorem underlying this kind of inference explains the data as generated by a stochastic process. How might a stochastic process of language change look like? Let us imagine the following graphic process of how languages might split up. This process is a bit bold and simple, but it is the best compromise connecting the mathematical intuition behind the mathematical structure called the “Yule tree prior” and descriptive population dynamics that I could imagine.\n",
    "\n",
    "Imagine an island region with difficult navigation between the islands, with one island, and later more, supporting an isolated language community with no contact to any other island.\n",
    "\n",
    "Once in a generation, each inhabited island sends out a boat to try to cross the turbulent seas and settle a new island. Five out of six boats sink in the process, but one in six boats reaches an uninhabited shore and founds a new village there, following the same tradition.\n",
    "\n",
    "How could we simulate this process?\n",
    "\n",
    "First, we need a function that describes the turbulences of the seas. Let us use a roll of a six-sided dice, likes this: Press Ctrl-Enter in the following cell to re-roll the die.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚀\n"
     ]
    }
   ],
   "source": [
    "print(roll_die())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "With that, we can model the crossing of the sea by “Roll a die. Iff you roll a ⚀, the crossing is successful and a new village/speech community is founded.” We can now write a function that takes the language tree at a given point in time and propagates it by one generation by rolling the die for each village. For now, I shall use “v” for the ancestral village, “•” for descendants of a village that stayed and “Δ” for successful sailors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def extend_by_one_generation(tree, success=\"⚀\"):\n",
    "    for village in tree.get_leaves():\n",
    "        if roll_die() in success:\n",
    "            village.add_descendant(newick.Node(\"{:}•\".format(village.name), \"1\"))\n",
    "            village.add_descendant(newick.Node(\"{:}Δ\".format(village.name), \"1\"))\n",
    "        else:\n",
    "            village.name += \"•\"\n",
    "            village.length = village.length + 1\n",
    "    return tree\n",
    "\n",
    "def many_generations_later(tree=None, n_generations=7, success=\"⚀\"):\n",
    "    if tree is None:\n",
    "        tree = newick.Node(\"v\", \"1\")\n",
    "    for i in range(n_generations):\n",
    "        extend_by_one_generation(tree, success)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "──v•••••••\n"
     ]
    }
   ],
   "source": [
    "tree = many_generations_later()\n",
    "print(tree.ascii_art())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v•••••••:8.0\n"
     ]
    }
   ],
   "source": [
    "print(tree.newick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This now describes a stochastic process of population spread. A different model might be that the sea is much less dangerous and the crossing succeeds in about half the cases, which we model as a dice roll of ⚀⚁⚂.\n",
    "\n",
    "We still assume that migration is always to a new, uninhabited place, and with no contact back. Both assumptions make the mathematical calculations sufficiently easy that I can both show them here, and use them in the computer models I run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 ┌─v•••••••\n",
      "                      ┌─v••••••──┤\n",
      "                      │          └─v••••••Δ\n",
      "           ┌─v•••─────┤\n",
      "           │          │          ┌─v•••Δ•••\n",
      "           │          └─v•••Δ••──┤\n",
      "           │                     └─v•••Δ••Δ\n",
      "──v••──────┤\n",
      "           │                     ┌─v••Δ••••\n",
      "           │          ┌─v••Δ•••──┤\n",
      "           │          │          └─v••Δ•••Δ\n",
      "           └─v••Δ•────┤\n",
      "                      │          ┌─v••Δ•Δ••\n",
      "                      └─v••Δ•Δ───┤\n",
      "                                 └─v••Δ•ΔΔ•\n"
     ]
    }
   ],
   "source": [
    "print(many_generations_later(success=\"⚀⚁⚂\").ascii_art())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "If you re-run these notebook cells a few times (Ctrl-Enter), or if you have a good mathematical intuition, you will notice that the second tree ends up usually far bigger than the first tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Bayes' Theorem\n",
    "\n",
    "Now, how does this help us reconstruct language trees? The example lets me show you how to use a mathematical property of probabilities, known as “Bayes' Theorem” after 18th century scholar Thomas Bayes. The theorem relates conditional probabilities. For our context here, “conditional probability” should be read as “How compatible are two facts”.\n",
    "\n",
    "For example, a high probability P(A|B) means that the fact A is very compatible with the fact B. A low ‘marginal’ or ‘prior’ probability P(B) can be read as a quantitative way of phrasing ‘I doubt B’.\n",
    "\n",
    "So let us assume we are really unsure whether the sea is difficult (⚀⚁⚂) or nigh impossible (⚀) to cross, so we take P(⚀⚁⚂)=P(⚀)=0.5\n",
    "\n",
    "Now we go to the region, and after some research there, we gather the data given above, which convinces us [P(X)=1] of the following two facts.\n",
    "\n",
    "- There are exactly these four languages spoken in the island region, no more.\n",
    "- There was a single ancestral village with the tradition described above 7 generations ago.\n",
    "\n",
    "How compatible is “the sea is difficult to cross” or “the seas is nigh impossible to cross” with this new data?\n",
    "\n",
    "Bayes' Theorem tells us that\n",
    "\n",
    "     P(S|D) = P(D|S) * P(S) / P(D)\n",
    "\n",
    "In this formula, S represents the possible options for the sea, or more generally our model. D is the data, in this case “there are four villages”.\n",
    "The P(D|S) in that formula is the reason we built the computer model above: This conditional probability is not just a measure of compatibility of beliefs, it is also a repeatable experiment like you might think of when you hear the term “probability”: We can run our two models many, many times and count how often we see D, that is, how often the tree has exactly 4 leaves.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05985"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(4 languages | 7 generations, ⚀)\n",
    "p_one = numpy.mean([len(many_generations_later(n_generations=7, success=\"⚀\").get_leaves())==4 for _ in range(10000)]) * 0.5\n",
    "p_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0136"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(4 languages | 7 generations, ⚀⚁⚂)\n",
    "p_three = numpy.mean([len(many_generations_later(n_generations=7, success=\"⚀⚁⚂\").get_leaves())==4 for _ in range(10000)]) * 0.5\n",
    "p_three\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We do not actually have P(D), but we can still calculate the P(S|D) values, the “posterior probabilities”, because we know they are probabilities, so their sum must be one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8148400272294077, 0.18515997277059223)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_one, p_three = p_one / (p_one + p_three), p_three / (p_one + p_three)\n",
    "p_one, p_three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "After looking at the data, we see that the ⚀ model is much more convincing than the ⚀⚁⚂ model.\n",
    "Where we were really unsure before, now we are quite convinced that ⚀ is correct.\n",
    "We can even put a number on how much better it is: The “Bayes Factor” in favour of ⚀ is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.400735294117647"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_one / p_three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Models of language evolution\n",
    "\n",
    "Now we have seen the basic principle of Bayes' Theorem in action, we can turn to language data.\n",
    "\n",
    "Just like for the split of speaker communities, we need an explicit stochastic model that describes how languages change over time. Let us take a stochastic version of the basic assumption of glottochronology and assume that words are replaced by new, unrelated words at some underlying constant speed.\n",
    "\n",
    "This is an obvious simplification, chosen for the illustration purposes here. The models actually used in phylogenetic inference are also always vast simplifications, but hopefully at least somewhat more robust than the one presented here.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "Explained.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
